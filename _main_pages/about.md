---
display: Oliver Richardson
short: about
colors:
    fg : '#000000'
    bg : '#FFFFFF'
    menu : '#BBBBBB'
    nav : '#F8F8F8'
    border : '#E7E7E7'
    shadow : '#e7e7e7'
glyph: user
order: 0
# subtitle: include(subtitle-links.md)
# special_css: /css/about.css
---

{% comment %}
{% capture subtitle %}
[[CV]](/files/cv.pdf)
[[Google Scholar]](https://scholar.google.com/citations?user=5_yI4jIAAAAJ)
[[Github]](https://github.com/orichardson)
[[DBLP]](https://dblp.org/pid/281/7499.html)
<!-- [[Twitter]]()
[[Instagram]]() -->
{% endcapture %}
{% endcomment %}


I am a theorist with a broad background in science, who loves to make pretty things out of code.
Currently, I am a fifth-year Computer Science PhD candidate at Cornell, advised by 
[Joe Halpern](http://www.cs.cornell.edu/home/halpern).
<!-- I am a theorist, but love to write code. -->
 <!-- with broad mathematical and scientific training. -->

<!-- I have broad interests and broad technical expertise. -->

My thesis work focuses primarily on a unifying theory of probabilistic modeling, that allow
for inconsistent beliefs. This theory is based on a class of grpahical models I invented called
[Probabilistic Dependency Graphs (PDGs)](https://orichardson.github.io/pdg/), which 
subsumes traditional graphical models, as well as many machine leraning models. 

<!-- Critically, PDGs can contain inconsistent probabilistic information, and that degree of inconsistency
turns out to be quite important. -->

{{ subtitle }}


